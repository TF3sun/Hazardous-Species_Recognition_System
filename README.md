# Hazardous-Species_Recognition_System
YOLOv5를 활용한 유해종 인식 시스템

생태 교란종은 생태계의 균형을 교란하거나 교란할 우려가 있는 생물이다. 이들을 관리하기 위해서 지속적인 추적을 통해 분포를 파악하는 것이 중요하나 이는 많은 인력의 도움이 필요하다. 이에 해당 시스템에서는 누구나 사용 가능한 앱을 만들어 생태 교란종을 인식하고 간편하게 신고하여 해당 종 분포에 대한 데이터를 쉽게 얻을 수 있도록 하는것을 목적으로 개발되었다.

해당 시스템은 모바일 앱을 통해 유해종을 인식하면 해당 위치정보를 서버측으로 전송하고 서버측에서는 데이터를 수집하여 분포도를 생성한다. 이를 위해 모바일 앱을 실행할 경우 카메라 화면이 뜨고 해당 영상을 내장된 딥러닝 모델로 전달한다. 각 생물의 이미지 데이터를 학습한 딥러닝 모델은 해당 전달받은 이미지를 통해 종의 분류작업을 실행하고 해당 종에 대한 정보를 앱 사용자에게 제공한다. 또한 해당 종이 유해종에 해당하는 경우 이를 알리고 촬영 위치정보 공유을 권유하는 메시지를 출력한다. 위치정보 전송 버튼을 클릭하게 되면 해당 위치와 인식한 종의 이름을 서버측으로 전송하게 된다. 서버측에서는 위치 데이터를 전송받고 이를 데이터베이스에 저장한다. 서버 운영자가 지도 생성 프로그램을 실행하게 되면 데이터베이스의 데이터를 불러와 html로 작성된 지도에 분포도를 그린후 파일로 저장하고 이를 지정된 이메일로 전송한다.

시스템의 하드웨어 구성은 모바일앱을 실행할 카메라와 GPS 및 통신이 가능한 스마트폰과 서버측을 구현을 위한 라즈베리파이를 사용하였다. 소프트웨어 구성은 모바일앱을 실행할 안드로이드11 이상 운영체제, 종을 분류한 딥러닝 모델, 서버측은 ubuntu 22.04 운영체제에 python3.10, 통신을 위한 flask, 데이터베이스를 구현할 sqlite3, 지도생성 folium, 메일전송 smtplib라이브러리를 사용하였다.

모델 학습 데이터 구축
GBIF에서 식물 이미지 데이터를 가져왔으며 3종의 식물에 대한 이미지를 roboflow을 통해 라벨링 작업을 수행하고 증상 작업을 통해 총 17,982개의 이미지, 타겟데이터를 구축하였다. 이중 train 15738, valid 1496, test748개로 나누었다.

모델 학습
앞서 생성한 데이터를 colab환경의 gpu를 통해 YOLOv5모델에 학습시켰다. 모델 성능은 평균 78.2% mAp를 기록하였으며, 클래스별 정확도는 가시박 83.5%, 환삼덩굴 77.8%, 가시상추 73.4%가 나왔다. 해당 모델을 안드로이드 앱에서 사용하기 위해 pytorch-lite를 사용해야함으로 가중치 파일은 ptl 파일로 저장하였다.

모바일 앱
구글 개발자 사이트(https://developer.android.com/media/camera/get-started-with-camera?hl=ko)의 cameraX 기본 모델을 사용하였다. 딥러닝 모델은 pytorch-lite를 사용하였으며 앞어 저장한 가중치 파일을 사용하였다.

해당 프로젝트에서는 3개의 유해종만을 학습하여 앱의 수요가 적을것이다. 그러나 모델에 유해종뿐만 아닌 다양한 생물종의 이미지 데이터를 학습시키게 된다면 일반인들에게 생물종 데이터를 쉽게 제공해주는 시스템을 구현하면 앱에 대한 수요를 늘릴 수 있을것으로 기대된다.
